
<html>
<head>
<style>
            body {font-family: Arial, sans-serif; line-height: 1.6; padding: 20px; background-color: #f5f5f5;}
            .job-card {background: white; border-radius: 10px; padding: 15px; margin-bottom: 20px; box-shadow: 0 2px 5px rgba(0,0,0,0.1);}
            .job-title {font-size: 18px; font-weight: bold;}
            .company-location {font-size: 16px; color: #666;}
            .keywords {font-style: italic; margin-top: 10px;}
            .description {margin-top: 0; white-space: pre-wrap;}
            .description ul {margin-top: 0;}
            a {color: #1a0dab; text-decoration: none;}
            a:hover {text-decoration: underline;}
        </style>
</head>
<body>
<h2>Top Job Matches</h2>
<div class="job-card">
<div class="job-title">#1 AI/ML Engineering Senior Advisor — Score: 0.52 (Raw: 0.52)</div>
<div class="company-location">Endava North America | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/ai-ml-engineering-senior-advisor-at-endava-north-america-4233745119?position=3&amp;pageNum=1&amp;refId=nGABQKSTTnP1iDYo%2Fet%2FwA%3D%3D&amp;trackingId=RuUK%2B33oEAqSmrhOgRcIKQ%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'models', 'AWS', 'optimization', 'object', 'PyTorch', 'tasks', 'machine', 'REST', 'Python', 'vision', 'TensorFlow', 'computer', 'model'}</div>
<div class="description">
<ul>
<li>Required:</li><li>7+ years of hands-on experience in applied machine learning, deep learning, and AI system deployment</li><li>Strong Python engineering background with ML/DL frameworks: TensorFlow, PyTorch, Keras, OpenCV</li><li>Proven experience in Computer Vision tasks, including object detection, segmentation, and OCR</li><li>Experience training and fine-tuning models such as: YOLOv5/v8, EfficientNet, Faster-RCNN, TrOCR, Vision Transformers (ViT)</li><li>Practical experience building and serving REST APIs for inference (TF Serving, TorchServe, FastAPI)</li><li>Hands-on with MLOps tools: DVC, MLflow, Git, CI/CD, containerization (Docker/Kubernetes)</li><li>Cloud deployment experience (Azure preferred; AWS or GCP acceptable)</li><li>LLM/GenAI experience: building, fine-tuning, or prompting models such as GPT-4, LLaMA, Claude, etc.</li><li>Familiarity with RAG (Retrieval-Augmented Generation) pipelines and integration into enterprise systems</li><li>Understanding of Agentic AI architectures (e.g., LangChain, CrewAI, AutoGPT) for orchestrated task agents or workflow automation</li><li>Strong foundations in statistics, optimization, and deep learning principles</li><li>Clear understanding of AI governance, fairness, and model explainability</li><li>Who are we:</li><li>GalaxE, now Endava, is a professional IT services firm that specializes in platform-driven solutions and the use of automation to achieve enterprise business transformation and mission-critical change for some of the largest companies in the world. Using our proprietary solution set, GxFource®, we apply machine learning techniques and predictive analytics tools as part of a broad artificial intelligence strategy that provides effective impact and data-driven business transformation.</li><li>Since its founding, GalaxE has been dedicated to advancing the benefits of technology. Recently, we have joined forces with Endava, to offer our employees global exposure and enhanced opportunities. As we continue that legacy and look to the future, a focus on business enablement through agile, cost-efficient, and effective integration of people, process, and technology anchors our success. We revolutionize change in the costs of doing business that transform companies and their ability to leap beyond the competition.</li><li>We value people and are committed to diversity and inclusion where our employees are made to feel comfortable and are encouraged to be authentic.</li><li>We are always looking for passionate, entrepreneurial-minded innovators and disrupters; game-changers that take ownership of the work they produce and bring it each and every day. Working with like-minded team members you will get a chance to discover, develop, and use cutting-edge technologies to transform the way we deliver creative business solutions.</li><li>Sound like you? Join us and find out for yourself what it means for you, and your career, to be part of the GalaxE team. Let’s build something, together.</li><li>*Equal Opportunity Employer/Veterans/Disabled</li><li>** Pay is based on several factors including market location and may vary depending on actual job-related knowledge, skills, and experience.</li><li>Physical Requirements:</li><li>Prolonged periods of remaining stationary at a desk and working on a computer</li><li>Must be able to lift to 15 lbs., as needed</li><li>Must be able to work on-site (corporate/client offices), as needed (not applicable for 100% remote roles)</li><li>Occasionally required to bend, kneel, crouch, and reach overhead.</li><li>Hand-eye coordination necessary to operate computers and various pieces of office equipment.</li><li>Specific vision abilities required include close vision, the ability to tolerate fluorescent lighting, and the ability to adjust focus.</li><li>Employees must be able to perform the physical requirements of the position satisfactorily and, if requested, reasonable accommodations will be made to enable employees requiring accommodations to perform the essential functions of their jobs, absent undue hardship.</li><li>For more information, please visit https://info.endava.com/galaxe-has-joined-endava</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#2 Senior Research Scientist (P4370) — Score: 0.50 (Raw: 0.50)</div>
<div class="company-location">84.51˚ | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-research-scientist-p4370-at-84-51%CB%9A-4257478312?position=7&amp;pageNum=5&amp;refId=vDKIMngglIBtKahSghUKVg%3D%3D&amp;trackingId=ZTnhbG9KTK6d%2F4vF3dKBLw%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'Docker', 'optimization', 'ML', 'PhD', 'model', 'transformer', 'sentence', 'models', 'contribution', 'time', 'NLP', 'tasks', 'data', 'modeling', 'language', 'methods', 'conferences', 'PyTorch', 'Science', 'Python', 'k', 'feedback', 'matching', 'cloud'}</div>
<div class="description">
<ul>
<li>Research and implement novel architectures for large language models and small language models</li><li>Lead research initiatives in model pretraining methodologies and optimization techniques</li><li>Develop advanced fine-tuning strategies including parameter-efficient methods (LoRA, adapters, etc.)</li><li>Specialize in encoder-only model architectures and their applications</li><li>Create and optimize embedding models for various downstream tasks</li><li>Conduct experiments to improve model efficiency, performance, and scalability</li><li>Write production-quality code for training, inference, and deployment of language models</li><li>Implement distributed training systems for large-scale model development</li><li>Optimize model architectures for computational efficiency and memory usage</li><li>Develop robust evaluation frameworks and benchmarking systems</li><li>Create reusable libraries and tools for the research team</li><li>Collaborate with cross-functional teams including ML engineers, product teams, and infrastructure</li><li>Mentor junior researchers and contribute to team knowledge sharing</li><li>Present research findings at conferences and publish in top-tier venues</li><li>Stay current with latest developments in NLP and deep learning research</li><li>PhD in Computer Science, Machine Learning, Artificial Intelligence, or related field</li><li>1-2 years of post-PhD industry or research experience in deep learning</li><li>Strong publication record in relevant conferences (NeurIPS, ICML, ICLR, ACL, EMNLP, etc.)</li><li>Expert proficiency in PyTorch; familiarity with distributed training frameworks (DeepSpeed, FairScale, etc.)</li><li>Hands-on experience with transformer architectures, attention mechanisms, and modern LLM/SLM implementations</li><li>Proven experience in pretraining large models, including data preprocessing, tokenization, and training dynamics</li><li>Deep understanding of supervised fine-tuning, RLHF, instruction tuning, and parameter-efficient methods</li><li>Specialized knowledge in BERT-style architectures, masked language modeling, and encoder-only applications</li><li>Experience developing and optimizing dense retrieval models, sentence embeddings, and multimodal embeddings</li><li>Ability to write clean, efficient, and scalable Python code suitable for production environments</li><li>Knowledge of model quantization, pruning, and other compression techniques</li><li>Experience with evaluation methodologies for language models</li><li>Experience with model versioning, experiment tracking (Weights &amp; Biases, MLflow), and deployment pipelines</li><li>Strong mathematical foundation in optimization, statistics, and linear algebra</li><li>Experience with cloud computing platforms (GCP, Azure) and containerization (Docker, Kubernetes)</li><li>Proficiency in distributed computing and parallel processing</li><li>Excellent problem-solving skills and ability to work independently</li><li>Strong communication skills for presenting complex technical concepts</li><li>Experience with multimodal models and cross-modal understanding</li><li>Familiarity with reinforcement learning from human feedback (RLHF)</li><li>Contributions to open-source deep learning projects</li><li>Experience with hardware optimization (GPUs, TPUs) and mixed-precision training</li><li>Background in natural language processing applications and linguistics</li><li>The stated salary range represents the entire span applicable across all geographic markets from lowest to highest. Actual salary offers will be determined by multiple factors including but not limited to geographic location, relevant experience, knowledge, skills, other job-related qualifications, and alignment with market data and cost of labor. In addition to salary, this position is also eligible for variable compensation.</li><li>Below is a list of some of the benefits we offer our associates:</li><li>Health: Medical: with competitive plan designs and support for self-care, wellness and mental health. Dental: with in-network and out-of-network benefit. Vision: with in-network and out-of-network benefit.</li><li>Wealth: 401(k) with Roth option and matching contribution. Health Savings Account with matching contribution (requires participation in qualifying medical plan). AD&amp;D and supplemental insurance options to help ensure additional protection for you.</li><li>Happiness: Hybrid work environment. Paid time off with flexibility to meet your life needs, including 5 weeks of vacation time, 7 health and wellness days, 3 floating holidays, as well as 6 company-paid holidays per year. Paid leave for maternity, paternity and family care instances.</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#3 Senior Machine Learning Engineer — Score: 0.48 (Raw: 0.48)</div>
<div class="company-location">Largeton Group | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-machine-learning-engineer-at-largeton-group-4266465240?position=9&amp;pageNum=0&amp;refId=tpX2%2BoTMGkfd7tjpAn087Q%3D%3D&amp;trackingId=6AJcJ59n3TofJjsc06viuA%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'models', 'endtoend', 'security', 'domains', 'Engineering', 'Docker', 'AWS', 'forecasting', 'machine', 'ML', 'SQL', 'PyTorch', 'Science', 'data', 'Python', 'modeling', 'cloud'}</div>
<div class="description">
<ul>
<li>Lead the design and implementation of end-to-end machine learning (ML) solutions covering data ingestion, ML processing, and results delivery/activation for algorithmic products.</li><li>Collaborate cross-functionally with data science, data engineering, and data architecture teams to architect, prototype, and productionize ML workflows.</li><li>Act as both a solutions architect and hands-on implementation engineer, guiding teams toward best-in-class algorithmic product implementations.</li><li>Develop and optimize ML models, including deep learning architectures, LLMs, and BERT-based classifiers for personalization, generative AI, forecasting, and decision science domains.</li><li>Implement distributed training workflows (e.g., PyTorch) and optimize models for hardware acceleration (GPU, TPU, AWS Inferentia/Trainium).</li><li>Design and build scalable ML infrastructure and AI services for both real-time streaming and offline batch use cases using AWS cloud services.</li><li>Enhance and maintain MLOps platforms, including Feature Store, ML Observability, ML Governance, and automated CI/CD pipelines.</li><li>Implement data processing workflows and ensure high-quality data ingestion, cleansing, and feature engineering.</li><li>Build and deploy models across cloud compute environments (EC2, EKS, SageMaker, etc.), leveraging infrastructure-as-code.</li><li>Monitor, profile, and optimize ML system performance for accuracy, latency, and cost efficiency.</li><li>Stay updated on the latest ML engineering patterns, AWS advancements, and best practices in cloud-based ML deployment.</li><li>Ensure all solutions meet data governance, security, and architectural standards in partnership with relevant teams.</li><li>Provide technical leadership, mentorship, and guidance on modeling and infrastructure to peers and partners.</li><li>Minimum 13+ years of experience in software/ML engineering (5+ years in cloud-based ML product solutions).</li><li>Master’s degree in Computer Science, Software Engineering, or related field.</li><li>Expertise in AWS, Python, SQL, PySpark, Docker.</li><li>Experience with MLOps, CI/CD, Agile methodology.</li><li>Strong communication and teamwork skills.</li><li>Experience in building ML systems at scale for both streaming and batch architectures.</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#4 Data Scientist, AWS Professional Services — Score: 0.48 (Raw: 0.48)</div>
<div class="company-location">Amazon Web Services (AWS) | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/data-scientist-aws-professional-services-at-amazon-web-services-aws-4244911493?position=4&amp;pageNum=1&amp;refId=nGABQKSTTnP1iDYo%2Fet%2FwA%3D%3D&amp;trackingId=5%2BAUWsgURJeEujxJjSvrhA%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'ML', 'PhD', 'model', 'transformer', 'models', 'AWS', 'orchestration', 'data', 'endtoend', 'vision', 'TensorFlow', 'computer', 'language', 'PyTorch', 'machine', 'Python', 'container', 'feedback', 'sample', 'cloud'}</div>
<div class="description">
<ul>
<li>Implementing end-to-end AI/ML and GenAI projects, from understanding business needs to data preparation, model development, solution deployment, and post-production monitoring</li><li>Collaborating with AI/ML scientists, engineers, and architects to research, design, develop, and evaluate AI algorithms and build ML systems and operations (MLOps) using AWS services to address real-world challenges</li><li>Interacting with customers directly to understand the business challenges, deliver briefing and deep dive sessions to customers and guide them on adoption patterns and paths to production</li><li>Creating and delivering best practice recommendations, tutorials, blog posts, publications, sample code, and presentations tailored to technical, business, and executive stakeholders</li><li>Providing customer and market feedback to product and engineering teams to help define product direction</li><li>Bachelor's degree or above in computer science, mathematics, statistics, machine learning or equivalent quantitative field</li><li>3+ years of building machine learning models for business application experience including predictive modelling, natural language processing, and deep learning</li><li>3+ years of hands-on experience with training, fine-tuning, evaluating, and deploying transformer models in production</li><li>2+ years of experience with cloud services related to machine learning (e.g., Amazon SageMaker) and coding with Python or R, using modern machine learning libraries and tools such as scikit-learn, TensorFlow, PyTorch.</li><li>Experience with technical customer-facing engagements</li><li>PhD in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field</li><li>AWS experience preferred, with proficiency in a range of AWS services (e.g., SageMaker, Bedrock, EC2, ECS, EKS, OpenSearch, VPC) and professional certifications (e.g., Solutions Architect Professional)</li><li>2+ years of experience with design, deployment, and evaluation of AI agents and orchestration approaches; experience with open source frameworks like LangChain, LangGraph, LlamaIndex, and/ or similar tools</li><li>5+ years of deep learning, computer vision, human robotic interaction, algorithms implementation experience using PyTorch or TensorFlow</li><li>Experience in launching AI applications in production on AWS</li><li>Experience building ML pipelines with MLOps best practices, including: data preprocessing, distributed &amp; GPU training, model deployment, monitoring, and retraining; experience with container and CI/CD pipelines</li><li>Strong communication skills, with attention to detail and ability to convey rigorous technical concepts and considerations to non-experts</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#5 Data Scientist, AWS Professional Services — Score: 0.48 (Raw: 0.48)</div>
<div class="company-location">Amazon Web Services (AWS) | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/data-scientist-aws-professional-services-at-amazon-web-services-aws-4244907717?position=5&amp;pageNum=1&amp;refId=nGABQKSTTnP1iDYo%2Fet%2FwA%3D%3D&amp;trackingId=3zXIk%2FwEbXZebPutT%2FrtEA%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'ML', 'PhD', 'model', 'transformer', 'models', 'AWS', 'orchestration', 'data', 'endtoend', 'vision', 'TensorFlow', 'computer', 'language', 'PyTorch', 'machine', 'Python', 'container', 'feedback', 'sample', 'cloud'}</div>
<div class="description">
<ul>
<li>Implementing end-to-end AI/ML and GenAI projects, from understanding business needs to data preparation, model development, solution deployment, and post-production monitoring</li><li>Collaborating with AI/ML scientists, engineers, and architects to research, design, develop, and evaluate AI algorithms and build ML systems and operations (MLOps) using AWS services to address real-world challenges</li><li>Interacting with customers directly to understand the business challenges, deliver briefing and deep dive sessions to customers and guide them on adoption patterns and paths to production</li><li>Creating and delivering best practice recommendations, tutorials, blog posts, publications, sample code, and presentations tailored to technical, business, and executive stakeholders</li><li>Providing customer and market feedback to product and engineering teams to help define product direction</li><li>Bachelor's degree or above in computer science, mathematics, statistics, machine learning or equivalent quantitative field</li><li>3+ years of building machine learning models for business application experience including predictive modelling, natural language processing, and deep learning</li><li>3+ years of hands-on experience with training, fine-tuning, evaluating, and deploying transformer models in production</li><li>2+ years of experience with cloud services related to machine learning (e.g., Amazon SageMaker) and coding with Python or R, using modern machine learning libraries and tools such as scikit-learn, TensorFlow, PyTorch</li><li>Experience with technical customer-facing engagements</li><li>PhD in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field</li><li>AWS experience preferred, with proficiency in a range of AWS services (e.g., SageMaker, Bedrock, EC2, ECS, EKS, OpenSearch, VPC) and professional certifications (e.g., Solutions Architect Professional)</li><li>2+ years of experience with design, deployment, and evaluation of AI agents and orchestration approaches; experience with open source frameworks like LangChain, LangGraph, LlamaIndex, and/ or similar tools</li><li>5+ years of deep learning, computer vision, human robotic interaction, algorithms implementation experience using PyTorch or TensorFlow</li><li>Experience in launching AI applications in production on AWS</li><li>Experience building ML pipelines with MLOps best practices, including: data preprocessing, distributed &amp; GPU training, model deployment, monitoring, and retraining; experience with container and CI/CD pipelines</li><li>Strong communication skills, with attention to detail and ability to convey rigorous technical concepts and considerations to non-experts</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#6 Senior Data Scientist, AWS Professional Services — Score: 0.46 (Raw: 0.46)</div>
<div class="company-location">Amazon Web Services (AWS) | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-data-scientist-aws-professional-services-at-amazon-web-services-aws-4244915064?position=2&amp;pageNum=2&amp;refId=RWE0GD2AzmDDTS8EfR3jvg%3D%3D&amp;trackingId=CZHRFGOXHmSKcDmED6CXGA%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'models', 'computer', 'AWS', 'container', 'ML', 'feedback', 'PhD', 'sample', 'PyTorch', 'orchestration', 'machine', 'data', 'model', 'vision', 'TensorFlow', 'cloud', 'transformer'}</div>
<div class="description">
<ul>
<li>Lead end-to-end AI/ML and GenAI projects, from understanding business needs to data preparation, model development, solution deployment, and post-production monitoring</li><li>Collaborate with AI/ML scientists, engineers, and architects to research, design, develop, and evaluate AI algorithms and build ML systems and operations (MLOps) using AWS services to address real-world challenges</li><li>Interact with customers directly to understand the business challenges, deliver briefing and deep dive sessions to customers and guide them on adoption patterns and paths to production</li><li>Create and deliver best practice recommendations, tutorials, blog posts, publications, sample code, and presentations tailored to technical, business, and executive stakeholders</li><li>Provide customer and market feedback to product and engineering teams to help define product direction</li><li>Master's degree in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field with 5+ years of experience; or bachelor's degree with 8+ years of experience</li><li>5+ years of building machine learning models for business application experience</li><li>3+ years of hands-on experience with training, fine-tuning, evaluating, and deploying transformer models in production</li><li>Experience with cloud services related to machine learning (e.g., Amazon SageMaker) and generative AI applications</li><li>Experience with technical customer-facing engagements, and strong communication skills, with attention to detail and ability to convey rigorous technical concepts and considerations to non-experts</li><li>PhD in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field</li><li>AWS experience preferred, with proficiency in a range of AWS services (e.g., SageMaker, Bedrock, EC2, ECS, EKS, OpenSearch, VPC) and professional certifications (e.g., Solutions Architect Professional)</li><li>2+ years of experience with design, deployment, and evaluation of AI agents and orchestration approaches; experience with open source frameworks like LangChain, LangGraph, LlamaIndex, and/ or similar tools</li><li>5+ years of deep learning, computer vision, human robotic interaction, algorithms implementation experience using PyTorch or TensorFlow</li><li>Experience in launching AI applications in production on AWS</li><li>Experience building ML pipelines with MLOps best practices, including: data preprocessing, distributed &amp; GPU training, model deployment, monitoring, and retraining; experience with container and CI/CD pipelines</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#7 Senior AI Developer — Score: 0.46 (Raw: 0.46)</div>
<div class="company-location">Publicis Re:Sources | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-ai-developer-at-publicis-re-sources-4255918794?position=6&amp;pageNum=3&amp;refId=AYOPD8R4at1nS26kc4g2JA%3D%3D&amp;trackingId=oU63MTbYe3Ur8F9RM3ARiQ%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'models', 'Engineering', 'language', 'AWS', 'API', 'ML', 'NLP', 'PyTorch', 'Data', 'Science', 'SQL', 'Python', 'TensorFlow', 'model'}</div>
<div class="description">
<ul>
<li>People First, Driving Success Together</li><li>Problem Solving Mindset</li><li>Respect Each Other</li><li>Partner and Collaborate as One Team</li><li>Commit to Quality and Standards</li><li>Innovate and Embrace the Future</li><li>Collaborate with software engineers, business stake holders and/or domain experts to translate business requirements into product features, tools, projects, AI/ML, NLP/NLU and deep learning solutions.</li><li>Develop, implement, and deploy AI/ML solutions.</li><li>Preprocess and analyze large datasets to identify patterns, trends, and insights.</li><li>Evaluate, validate, and optimize AI/ML models to ensure their accuracy, efficiency, and generalizability.</li><li>Deploy applications and AI/ML model into cloud environment such as AWS/Azure/GCP etc.</li><li>Monitor and maintain the performance of AI/ML models in production environments, identifying opportunities for improvement and updating models as needed.</li><li>Document AI/ML model development processes, results, and lessons learned to facilitate knowledge sharing and continuous improvement.</li><li>Bachelor's or master’s degree in Computer Science, Data Science, Engineering, or a related field.</li><li>Strong programming skills in languages such as Python, SQL etc.</li><li>Exposure to GEN AI models such as OpenAI, Google Gemini, Runway ML etc.</li><li>Experience in developing and deploying AI/ML and deep learning solutions with libraries and frameworks, such as TensorFlow, PyTorch, Scikit-learn, OpenCV and/or Keras.</li><li>Knowledge of math, probability, and statistics.</li><li>Familiarity with a variety of Machine Learning, NLP, and deep learning algorithms.</li><li>Exposure in developing API using Flask/Django.</li><li>Good experience in cloud infrastructure such as AWS, Azure or GCP</li><li>Exposure to Gen AI, Vector DB/Embeddings, LLM (Large language Model)</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#8 Amazon Q Builder, Amazon Q Customer Success Team (Q-CST) — Score: 0.41 (Raw: 0.41)</div>
<div class="company-location">Amazon Web Services (AWS) | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/amazon-q-builder-amazon-q-customer-success-team-q-cst-at-amazon-web-services-aws-4244515107?position=8&amp;pageNum=10&amp;refId=ncL5TgLN%2FXa4OOwEg6JeWg%3D%3D&amp;trackingId=JkAjpG0GzWvXpmCsNGq7Gg%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'security', 'language', 'AWS', 'SQL', 'data'}</div>
<div class="description">
<ul>
<li>Design and implement enterprise-scale Generative AI solutions using Amazon Q and AWS AI/ML services</li><li>Create strategies for optimizing AI application performance, scalability, and cost-effectiveness</li><li>Foster knowledge sharing and develop reusable frameworks for AI application deployment</li><li>Guide cross-functional teams in integrating AI solutions while considering user experience and accessibility</li><li>Ensure security compliance and best practices in AI implementation</li><li>3+ years of design, implementation, or consulting in applications and infrastructures</li><li>2+ years of experience with one of the following: SQL, Business Intelligence platforms, data engineering</li><li>2+ years of software development with object-oriented language experience</li><li>2+ years of experience developing dashboards with a Business Intelligence platform such as QuickSight, Tableau, PowerBI, Looker, Thoughtspot, Microstrategy, Sisense, Domo, etc.</li><li>1+ years of AI/ML implementation or experimentation (e.g., Generative AI, Generative BI, Agentic AI)</li><li>Experience leading the architecture and implementation of AI/ML workloads</li><li>Proven track record of delivering robust, scalable solutions in complex technical environments as well as delivering successful enterprise-scale Gen AI implementations</li><li>International consulting or professional services sales and delivery experience</li><li>Strong track record of CI/CD implementation in enterprise environments</li><li>Strong communication skills with the ability to explain technical concepts to both technical and non-technical audiences</li><li>Experience with selling consulting/professional services</li><li>Bachelor's degree, or 5+ years of professional or military experience</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#9 Artificial Intelligence Engineer — Score: 0.41 (Raw: 0.41)</div>
<div class="company-location">CareerVest | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/artificial-intelligence-engineer-at-careervest-4267967142?position=10&amp;pageNum=0&amp;refId=tpX2%2BoTMGkfd7tjpAn087Q%3D%3D&amp;trackingId=oAlaiI8dJ20LKgBwKD1o0w%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'Development', 'language', 'rate', 'NLP', 'Science'}</div>
<div class="description">
<ul>
<li>CareerVest is committed to helping Indian students in the USA secure IT job placements after completing their undergraduate or master's programs. With over 74 successful placements and an 87.4% success rate, we specialize in career counseling, interview support, IT training, personalized recruiter assistance, skills upgrade programs, and resume enhancement services. With 9+ years of expertise in job placements, CareerVest is your partner for full-time job offerings, robust training, and resume-building services.</li><li>This is a full-time on-site role for an Artificial Intelligence Engineer located in Chicago, IL. The role involves designing, implementing, and maintaining AI systems, focusing on neural networks, natural language processing (NLP), and pattern recognition. The candidate will work closely with software development teams to integrate AI solutions and ensure their performance and scalability.</li><li>Knowledge in Pattern Recognition and Neural Networks</li><li>Strong foundation in Computer Science</li><li>Experience in Software Development</li><li>Expertise in Natural Language Processing (NLP)</li><li>Excellent problem-solving and analytical skills</li><li>Ability to work collaboratively in a team environment</li><li>Master's degree in Computer Science, Artificial Intelligence, or related field preferred</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#10 Sr Machine Learning Engineer — Score: 0.40 (Raw: 0.40)</div>
<div class="company-location">The Hartford | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/sr-machine-learning-engineer-at-the-hartford-4268109972?position=9&amp;pageNum=1&amp;refId=nGABQKSTTnP1iDYo%2Fet%2FwA%3D%3D&amp;trackingId=A4mCUK27JbVtT4rJMBkzmQ%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'Development', 'endtoend', 'Docker', 'realtime', 'AWS', 'time', 'API', 'ML', 'feedback', 'Data', 'orchestration', 'Science', 'data', 'Python', 'cloud', 'model'}</div>
<div class="description">
<ul>
<li>We build artificial intelligence/machine learning solutions, not models. We support end-to-end business problems with a focus on systems design.</li><li>We are trusted and transparent, collaborating closely with our partners and considering their capacity for change.</li><li>Our products are delivered with full monitoring solutions to ensure they continue to perform as expected.</li><li>We listen carefully to our customers and become partners in problem-solving with humble confidence.</li><li>We deliver minimally viable products first and expand their sophistication over time based on feedback.</li><li>Research, experiment with, and implement suitable frameworks, tools, and technologies to enable AI/ML decision-making at scale.</li><li>Participate in identifying and assessing opportunities, such as the value of new data sources and analytical techniques, to ensure ongoing competitive advantage.</li><li>Review work with leadership and partners on an ongoing basis to calibrate deliverables against expectations.</li><li>Accountable for the ownership of design, development, and maintenance of MLOps and GenAI platforms and services.</li><li>Work with junior engineers and peers to provide mentorship and thought leadership.</li><li>Collaborate with partners Enterprise Data, Data Science, Business, Cloud Enablement Team, and Enterprise Architecture teams.</li><li>Delivery of critical milestones for model deployment in the Google Cloud Platform (GCP) and AWS cloud.</li><li>Develop, adopt, and promote MLOps best practices to the Data Science community.</li><li>Implement infrastructure-as-code using Terraform or CloudFormation to automate deployments.</li><li>Contribute to the development of agentic AI capabilities and support experimentation with LLMs and GenAI frameworks.</li><li>Must be authorized to work in the U.S. now and in the future.</li><li>Bachelor's degree in related field and 5+ years of experience.</li><li>Solid understanding of ML lifecycle: model training, deployment, monitoring, and feedback loops.</li><li>Strong application development experience using Python.</li><li>3+ years of hands-on experience developing with one of the public clouds including tools and techniques to auto scale systems.</li><li>Experience with CI/CD and IAC tools (e.g., terraform, Jenkins, GitHub Actions) and containerization (Docker, Kubernetes).</li><li>Good understanding of Generative AI technologies, frameworks, key LLMs, and architecture patterns.</li><li>Exposure to agentic AI architectures and prompt engineering.</li><li>Good understanding and experience building orchestration framework for real-time and batch model services.</li><li>Good understanding of various model development algorithms and types of ML use cases e.g., regression, classification, etc.</li><li>Strong fundamental knowledge of data structures and algorithms</li><li>Development experience for WebService API with AWS suite of Tools.</li><li>Familiarity with big data technologies (i.e., Hadoop, Spark, Hive, etc.) and RDBMS.</li><li>Hands-on experience with public cloud GCP, especially Vertex AI, Cloud Run, BigQuery, and GKE.</li><li>Basic understanding of ML frameworks i.e., Tensorflow, Scikit Learn, etc.</li><li>Experience with Agile framework and scrum/Kanban based project management.</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#11 Data Scientist — Score: 0.40 (Raw: 0.40)</div>
<div class="company-location">L.E.K. Consulting | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/data-scientist-at-l-e-k-consulting-4268278028?position=3&amp;pageNum=0&amp;refId=tpX2%2BoTMGkfd7tjpAn087Q%3D%3D&amp;trackingId=yoYa875tmjf942VxB0awSA%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'   ', 'optimization', 'ML', 'model', 'models', 'Engineering', 'AWS', 'time', 'NLP', 'data', 'modeling', 'TensorFlow', 'manipulation', 'Airflow', 'PyTorch', 'Data', 'Science', 'machine', 'Python', 'service', 'Scientist', 'SQL', 'analysis', 'cloud'}</div>
<div class="description">
<ul>
<li>Support end-to-end data science projects from conceptualization through to deployment, and deploy advanced machine learning models in clients' cloud environments, optimizing for scalability, performance, and reliability to address specific business challenges and objectives</li><li>Support clients in strategically leveraging technical models, guiding them through the interpretation of results and the integration of actionable insights into their business workflows.</li><li>Solve a wide variety of complex analytical challenges for clients, sometimes dynamically balancing multiple client engagements at one time</li><li>Analytical needs can include: data aggregation / creation, data cleaning / manipulation, commercial data science (e.g., geospatial, machine learning, predictive modelling, NLP, GenAI etc.), and visualizations</li><li>Help drive the technical roadmap needed to support client engagements</li><li>Drive the development of state-of-the-art analytical apps, leveraging up-to-date in machine learning algorithms to solve complex problems</li><li>Collaborate with a variety of stakeholders to continuously innovate on the apps, service lines and proprietary data assets we can offer</li><li>Provide technical expertise and thought leadership on developing analytical tools, services lines, and proprietary data assets, and contribute to building these areas directly when applicable</li><li>Uphold best-in-class standards in app development, data integrity, and ensuring solutions are both scalable and maintainable</li><li>When relevant, support Managing Directors in developing and delivering client proposals where advanced data and analytics are critical to the scope of work</li><li>Provide input into training / upskilling the D&amp;A team provides to Managing Directors to ensure they are aware of all of our most current capabilities</li><li>Stay up to date on best-in-class software, tools, and techniques to ensure that we are able to provide clients with best-in-class solutions</li><li>Support commercialization and upskilling of staff on relevant software, tools and techniques</li><li>Help drive the technical roadmap to ensure we are operating a best-in-class Data &amp; Analytics function</li><li>Degree in a quantitative and/or business discipline preferred, examples include: Statistics, Computer Science, Data Science, Mathematics, Operations Research, Engineering, Economics</li><li>A minimum of 2 years of experience in applied data science with a solid foundation in machine learning, statistical modeling, and analysis is required for a Data Scientist</li><li>Strong knowledge, experience, and fluency in a wide variety of tools including Python with data science and machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch), Spark, SQL; familiarity with Alteryx and Tableau preferred</li><li>Technical understanding of machine learning algorithms; experience with deriving insights by performing data science techniques including classification models, clustering analysis, time-series modeling, NLP; technical knowledge of optimization is a plus</li><li>Expertise in developing and deploying machine learning models in cloud environments (AWS, Azure, GCP) with a deep understanding of cloud services, architecture, and scalable solutions. (e.g., Sagemaker, Azure ML, Kubernetes, Airflow)</li><li>Demonstrated experience with MLOps practices, including continuous integration and delivery (CI/CD) for ML, model versioning, monitoring, and performance tracking to ensure models are efficiently updated and maintained in production environments</li><li>Hands-on experience with manipulating and extracting information on a variety of large both structured and unstructured datasets; comfort with best data acquisition and warehousing practices</li><li>Experience with commercial business analytics; experience at a consulting firm / agency is a plus</li><li>Proficient Excel, PowerPoint presentation and excellent communication skills, both written and oral; ability to explain complex algorithms to business stakeholders</li><li>Ability to achieve results through others; experience and proven success record working in matrix, agile and fast-growing environments; and assertive, intellectually curious and continuously driving towards excellence.</li><li>L.E.K. Consulting is an Equal Opportunity Employer</li><li>L.E.K. Consulting has a hybrid work model in place for our U.S. offices.</li><li>In California, Illinois, and New York the base salary is between $85,000 - $120,000 (USD); placement within this range will vary based on experience and skill level. L.E.K. also offers a performance bonus, profit sharing and other benefits.</li><li>In other locations, competitive pay is commensurate with the role and geography.</li><li>Applicants for this position must be legally authorized to work in the United States on a permanent basis without the need for employer sponsorship. Unfortunately, we are unable to consider candidates requiring sponsorship for visas, including but not limited to TN, H1-B, F-1, STEM OPT/CPT, or any other work authorization.</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#12 Senior Data Engineer (Python) — Score: 0.38 (Raw: 0.38)</div>
<div class="company-location">Capital One | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-data-engineer-python-at-capital-one-4257457070?position=1&amp;pageNum=17&amp;refId=bMY%2F6kKx9gG3xlxX18UFLw%3D%3D&amp;trackingId=CQhwILpCZX7sL%2F6yDMd0gw%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'realtime', 'AWS', 'test', 'machine', 'SQL', 'Python', 'cloud', 'data'}</div>
<div class="description">
<ul>
<li>Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies</li><li>Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems</li><li>Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake</li><li>Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal &amp; external technology communities, and mentoring other members of the engineering community</li><li>Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment</li><li>Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance</li><li>Bachelor’s Degree</li><li>At least 3 years of experience in application development (Internship experience does not apply)</li><li>At least 1 year of experience in big data technologies</li><li>5+ years of experience in application development including Python, SQL, Scala, or Java</li><li>2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)</li><li>3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)</li><li>2+ year experience working on real-time data and streaming applications</li><li>2+ years of experience with NoSQL implementation (Mongo, Cassandra)</li><li>2+ years of data warehousing experience (Redshift or Snowflake)</li><li>3+ years of experience with UNIX/Linux including basic commands and shell scripting</li><li>2+ years of experience with Agile engineering practices</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#13 AI Engineer — Score: 0.38 (Raw: 0.38)</div>
<div class="company-location">Daniels Health | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/ai-engineer-at-daniels-health-4268607968?position=6&amp;pageNum=0&amp;refId=tpX2%2BoTMGkfd7tjpAn087Q%3D%3D&amp;trackingId=Q21W73rpWJxLg%2BO9ogMCJg%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'models', 'realtime', 'machine', 'ETL', 'Data', 'SQL', 'control', 'Scientist', 'Science', 'data', 'Python', 'modeling', 'pipeline', 'model'}</div>
<div class="description">
<ul>
<li>We are seeking a skilled AI Engineer to join our dynamic data team, supporting cutting-edge AI initiatives. You will design and maintain scalable data pipelines to fuel machine learning models and analytics, using tools like Databricks, Azure, Fivetran, and SQL. As part of a collaborative team you will ensure high-quality, accessible data to drive impactful AI solutions.</li><li>What you will doBuild and optimize ETL/ELT pipelines using Databricks and Fivetran to ingest, transform, and prepare data for AI model training and inference.  Design and manage data storage and processing solutions on Azure (e.g., Azure Data Lake, Azure Data Factory, Synapse Analytics) to support large-scale AI workloads.  Ensure data integrity, consistency, and reliability through robust validation and monitoring processes, leveraging SQL for querying and transformations.  Collaborate with the Data Scientist to preprocess and structure datasets for machine learning, including feature engineering and real-time data feeds.  Automate data workflows to streamline ingestion, transformation, and delivery processes, ensuring efficiency and scalability.  Monitor and optimize pipeline performance on Databricks and Azure to handle large datasets and meet AI system requirements.  Work closely with Data Analysts and business stakeholders to align data solutions with analytical and AI-driven business needs. Stay updated on AI and data engineering trends, recommending new tools or approaches to enhance pipeline efficiencyCandidate ProfileSkills &amp; QualificationsBachelor’s degree in Computer Science, Data Science, Business Analytics, or a related field. Master’s degree is a plus3+ years of experience in data engineering, with a focus on AI or machine learning projects. Expertise in building and optimizing ETL/ELT pipelines for AI applicationsHands-on expertise with Databricks for data processing and pipeline development.  Experience with Fivetran for data integration and ETL processesStrong SQL skills for querying, data modeling, and transformations. Knowledge of Python or Scala for scripting and automation within DatabricksExperience with data warehousing and lakehouse architecturesFamiliarity with distributed systems and big data tools (e.g., Apache Spark, Hadoop)Familiarity with version control (e.g., Git) and CI/CD pipelinesDatabricks Certified Data Scientist or Data Engineer certification is a plusStrong problem-solving skills and attention to detail. Effective communication to collaborate with technical and non-technical stakeholdersAbility to work in a fast-paced, team-oriented environmentWork EnvironmentOccasional travel necessary to accommodate for global and regional meetings, workshops or trainingAbility to occasionally join calls before / after traditional office hours</li><li>Build and optimize ETL/ELT pipelines using Databricks and Fivetran to ingest, transform, and prepare data for AI model training and inference.</li><li>Design and manage data storage and processing solutions on Azure (e.g., Azure Data Lake, Azure Data Factory, Synapse Analytics) to support large-scale AI workloads.</li><li>Ensure data integrity, consistency, and reliability through robust validation and monitoring processes, leveraging SQL for querying and transformations.</li><li>Collaborate with the Data Scientist to preprocess and structure datasets for machine learning, including feature engineering and real-time data feeds.</li><li>Automate data workflows to streamline ingestion, transformation, and delivery processes, ensuring efficiency and scalability.</li><li>Monitor and optimize pipeline performance on Databricks and Azure to handle large datasets and meet AI system requirements.</li><li>Work closely with Data Analysts and business stakeholders to align data solutions with analytical and AI-driven business needs.</li><li>Stay updated on AI and data engineering trends, recommending new tools or approaches to enhance pipeline efficiency</li><li>Skills &amp; Qualifications</li><li>Bachelor’s degree in Computer Science, Data Science, Business Analytics, or a related field. Master’s degree is a plus</li><li>3+ years of experience in data engineering, with a focus on AI or machine learning projects.</li><li>Expertise in building and optimizing ETL/ELT pipelines for AI applications</li><li>Hands-on expertise with Databricks for data processing and pipeline development.</li><li>Experience with Fivetran for data integration and ETL processes</li><li>Strong SQL skills for querying, data modeling, and transformations.</li><li>Knowledge of Python or Scala for scripting and automation within Databricks</li><li>Experience with data warehousing and lakehouse architectures</li><li>Familiarity with distributed systems and big data tools (e.g., Apache Spark, Hadoop)</li><li>Familiarity with version control (e.g., Git) and CI/CD pipelines</li><li>Databricks Certified Data Scientist or Data Engineer certification is a plus</li><li>Strong problem-solving skills and attention to detail.</li><li>Effective communication to collaborate with technical and non-technical stakeholders</li><li>Ability to work in a fast-paced, team-oriented environment</li><li>Work Environment</li><li>Occasional travel necessary to accommodate for global and regional meetings, workshops or training</li><li>Ability to occasionally join calls before / after traditional office hours</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#14 Senior Data Platform Engineer — Score: 0.38 (Raw: 0.38)</div>
<div class="company-location">BetterUp | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-data-platform-engineer-at-betterup-4212804756?position=9&amp;pageNum=15&amp;refId=cKOX0mBMcZqDAdPdpuPYIw%3D%3D&amp;trackingId=h2N%2FuGqCzVEBwie3CBNWoQ%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'Development', 'security', 'contribution', 'time', 'search', 'k', 'analysis', 'Airflow', 'ML', 'data', 'Python', 'vision'}</div>
<div class="description">
<ul>
<li>Architect, build, and maintain data systems that are delivering on end customer value</li><li>Centralize and standardize data collection, data transformation and analysis, data storage, and data serving approaches and processes</li><li>Support our ML / GenAI teams and functionality with platform capabilities for data delivery, processing, and infrastructure</li><li>Support our reporting and analytics teams in delivering both internal and customer-facing business insights</li><li>Stay current with emerging technologies and trends in a fast-evolving tech nology ecosystem</li><li>Operationally managing our data infrastructure, vendors, tooling, and processes</li><li>Strong programming background (e.g. Python)</li><li>Operational maturity (e.g. CI/CD systems, Infrastructure as Code, Kubernetes, monitoring, distributed systems, security and privacy best practices, etc.)</li><li>Experience in building and maintaining analytics stacks (e.g. Snowflake, dbt, Looker)</li><li>Running GenAI / ML systems in production (e.g. MLOps tooling, vector search, embedding stores, feature engineering at scale, etc.)</li><li>Architecting data systems (e.g. Airflow, Kafka, general system design)</li><li>Radical curiosity and a love for learning new things.</li><li>Strong problem-solving skills with a strategic mindset.</li><li>Ability to work autonomously while being great at collaboration.</li><li>Passion for BetterUp’s mission and a demonstrated ability to mentor and lead with empathy, passion, and wisdom.</li><li>Ability to navigate complex technical challenges, ensuring robust, flexible solutions that align with BetterUp’s long-term vision.</li><li>Experience bridging the gaps between data science, engineering, operations, security, and product teams.</li><li>Access to BetterUp coaching; one for you and one for a friend or family member</li><li>A competitive compensation plan with opportunity for advancement</li><li>Full coverage for medical, dental and vision insurance</li><li>Employer Paid Life, AD&amp;D, STD and LTD insurance</li><li>Flexible paid time off</li><li>Per year:</li><li>13 paid holidays</li><li>4 BetterUp Inner Work days (https://www.betterup.co/inner-work)</li><li>5 Volunteer Days to give back</li><li>Learning and Development stipend</li><li>Holiday charitable contribution of your choice on behalf of BetterUp</li><li>401(k) self contribution</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#15 Senior Software Engineer - Trading Data Fabric — Score: 0.37 (Raw: 0.37)</div>
<div class="company-location">Belvedere Trading, LLC | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-software-engineer-trading-data-fabric-at-belvedere-trading-llc-4182346343?position=5&amp;pageNum=12&amp;refId=Jd49uZ35ItIXHklDNFXfMw%3D%3D&amp;trackingId=lRYjihHomDlzmRDV4aJaBA%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'security', 'Technologies', 'Pandas', 'Data', 'data', 'Python', 'cloud'}</div>
<div class="description">
<ul>
<li>Lead the design and development of features and capabilities within our proprietary research platform for engineers, quants, traders and executives</li><li>Identify and leverage cloud, commercial and open-source technologies to accelerate our roadmap</li><li>Efficiently facilitate decisions by analyzing risk, effort, cost and benefit</li><li>Solve our most complex technical challenges while leaving a legacy of documented and reliable code</li><li>Innovate in both greenfield and existing projects, driving impactful improvements and new feature development</li><li>Support the continuous operation of live systems capturing and processing critical trading business data</li><li>Mentor other engineers in your areas of expertise</li><li>Work in a collaborative team environment encouraging constant learning and innovation from all levels of the company to build the future of technology and finance</li><li>Participate in our in-house learning and development curriculum via peer-led lectures to obtain knowledge about the fundamentals of trading and our proprietary trading systems</li><li>Expert-level Python knowledge, passionate about building robust, data-driven systems.</li><li>You’ll work with: Pandas for high-performance data wrangling and transformation, Google Cloud Platform (GCP) libraries to integrate seamlessly with cutting-edge Cloud Technologies, and Dash to craft interactive web-based dashboards used daily by decision-makers and engineers</li><li>Delivery Leader – Previously led delivery of new APIs and data centric Services to production</li><li>Cloud Native – Intuitive understanding of Cloud technologies for compute, storage and security</li><li>Data Specialist – Experience integrating traditional databases (e.g. PostgreSQL) and APIs with modern Data Warehouses (e.g. BigQuery, Snowflake), Streaming Frameworks (e.g. Pulsar)</li><li>Performance Minded – Expertly track and optimize performance and costs with tools, metrics and scalable designs</li><li>Business Mindset – Engage with traders and analysts across the company to better understand their needs and design solutions that will be readily adopted</li><li>Strong Communicator – Engage with teams and business units, sourcing new ideas and reaching consensus on shared initiatives</li><li>Streaming frameworks like Apache Beam, Spark, or Flink</li><li>JVM languages such as Java, Kotlin, or Scala</li><li>Spring Boot or similar backend frameworks</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#16 C++ Engineer — Score: 0.37 (Raw: 0.37)</div>
<div class="company-location">Jobs via eFinancialCareers | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/c%2B%2B-engineer-at-jobs-via-efinancialcareers-4225649553?position=3&amp;pageNum=22&amp;refId=UllS1LokqdhtEGj11Do5cQ%3D%3D&amp;trackingId=ZVS9I%2FARLIWrlXE7GZBroQ%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'computer', 'C'}</div>
<div class="description">
<ul>
<li>Expert knowledge of C++ in a latency-critical environment</li><li>At least 3 years of experience</li><li>A degree in computer science or a related field from a leading university</li><li>Preferred but not required: buyside/HFT experience.</li><li>Market-leading compensation packages – all cash!</li><li>Access to state-of-the-art technology – C++ 20 and beyond</li><li>Collaboration with top engineers, quants, and researchers</li><li>A tech-focused culture with hybrid working.</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#17 Senior Security Engineer — Score: 0.37 (Raw: 0.37)</div>
<div class="company-location">Morningstar | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-security-engineer-at-morningstar-4256318736?position=2&amp;pageNum=24&amp;refId=ZxskHQlzT0rEg%2FJcN5OIVQ%3D%3D&amp;trackingId=t4vpt2g46Cba1Go%2BjH2UkA%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'security', 'effectiveness', 'AWS', 'k', 'Python'}</div>
<div class="description">
<ul>
<li>Lead security detection and response initiatives, ensuring effective threat monitoring, investigation, and mitigation.</li><li>Develop and maintain security detections across SIEM, SOAR, and EDR platforms.</li><li>Architect and optimize security automation workflows to enhance threat response efficiency.</li><li>Collaborate with our in-house SOC and IT teams to refine detection and preventative capabilities and reduce false positives.</li><li>Research and implement new security technologies and best practices to enhance monitoring and response effectiveness.</li><li>Perform security assessments, tuning detection rules, and developing playbooks for security incidents.</li><li>Mentor junior engineers and contribute to security strategy and roadmap planning.</li><li>4+ years of hands-on experience in security engineering, threat detection, and response.</li><li>Strong expertise with SIEM, SOAR, and EDR.</li><li>Experience developing and tuning detections using logs, telemetry, and threat intelligence.</li><li>Proficiency in scripting and automation (Python, PowerShell, Bash, etc.).</li><li>Strong understanding of attack techniques (MITRE ATT&amp;CK framework) and incident response methodologies.</li><li>Ability to analyze security telemetry, investigate threats, and develop effective mitigation strategies.</li><li>Excellent communication skills and ability to collaborate across teams.</li><li>Experience with cloud security monitoring (AWS, Azure, GCP).</li><li>Familiarity with security frameworks (NIST, CIS, ISO 27001).</li><li>Certifications such as GIAC (GCDA, GCIH, GCFA), OSCP, CISSP, or relevant credentials.</li><li>Financial Health</li><li>75% 401k match up to 7%</li><li>Stock Ownership Potential</li><li>Company provided life insurance - 1x salary + commission</li><li>Physical Health</li><li>Comprehensive health benefits (medical/dental/vision) including potential premium discounts and company-provided HSA contributions (up to $500-$2,000 annually) for specific plans and coverages</li><li>Additional medical Wellness Incentives - up to $300-$600 annual</li><li>Company-provided long- and short-term disability insurance</li><li>Emotional Health</li><li>Trust-Based Time Off</li><li>6-week Paid Sabbatical Program</li><li>6-Week Paid Family Caregiving Leave</li><li>Competitive 8-24 Week Paid Parental Bonding Leave</li><li>Adoption Assistance</li><li>Leadership Coaching &amp; Formal Mentorship Opportunities</li><li>Annual Education Stipend</li><li>Tuition Reimbursement</li><li>Social Health</li><li>Charitable Matching Gifts program</li><li>Dollars for Doers volunteer program</li><li>Paid volunteering days</li><li>15+ Employee Resource &amp; Affinity Groups</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#18 Senior Data Scientist — Score: 0.37 (Raw: 0.37)</div>
<div class="company-location">Grindr | Chicago, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-data-scientist-at-grindr-4267539879?position=1&amp;pageNum=1&amp;refId=nGABQKSTTnP1iDYo%2Fet%2FwA%3D%3D&amp;trackingId=Ah%2Fme09NNPYGiBCCruDE0w%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'BS', 'machine', 'K', 'analysis', 'ML', 'Jupyter', 'SQL', 'Data', 'Science', 'data', 'Python', 'vision'}</div>
<div class="description">
<ul>
<li>Define and track key product metrics in collaboration with cross-functional partners</li><li>Design, run, and analyze A/B tests to evaluate the impact of new features</li><li>Perform data deep dives to explain trends and uncover actionable insights</li><li>Communicate findings clearly to stakeholders and influence product decisions</li><li>Build dashboards and tools to help teams monitor metrics and make data-informed decisions</li><li>Contribute to the development of best practices within the Data Science team</li><li>Explore and prototype ML applications to improve product quality (e.g., recommendations, spam detection)</li><li>BS or higher in Computer Science, Statistics, Mathematics, Physics, a related quantitative field, or equivalent experience</li><li>4+ years of industry data science experience</li><li>Strong communication skills and comfort working with cross-functional partners</li><li>Proficiency in Python for data analysis (e.g., pandas, Jupyter)</li><li>Strong SQL skills and experience working with large-scale data</li><li>Solid foundation in statistics and experimental design</li><li>Familiarity with BI tools like Looker, Tableau, or PowerBI</li><li>Some exposure to big data tools like Spark is a plus</li><li>Exposure to machine learning, especially practical tradeoffs in product settings</li><li>Experience with experimentation platforms like Statsig</li><li>Clear communication style and interest in mentoring peers or sharing best practices</li><li>Mission and Impact: Grindr is building the global gayborhood in your pocket. Your role will impact the lives of millions of LGBTQ+ people around the world. Through our success, we are making a world where the lives of our community are free, equal, and just.</li><li>Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents.</li><li>Retirement Savings: Generous 401K plan with 6% match and immediate vest in the U.S.</li><li>Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs.</li><li>Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more.</li><li>Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, food, and commuting, breakfast/lunch provided onsite, and yearly travel &amp; leisure stipend.</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#19 Senior Data Analyst — Score: 0.36 (Raw: 0.36)</div>
<div class="company-location">Univar Solutions | Downers Grove, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/senior-data-analyst-at-univar-solutions-4267563769?position=8&amp;pageNum=23&amp;refId=kjnqznZ1id3nBzi5v63zWg%3D%3D&amp;trackingId=FwUZ9IUdEKoIBgPNgeYsKg%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'models', 'MATLAB', 'Engineering', '   ', 'time', 'k', 'analysis', 'Data', 'SQL', 'Advanced', 'Science', 'data', 'Python', 'vision', 'matching'}</div>
<div class="description">
<ul>
<li>Develop reports, models, scorecards, and dashboards by gathering and transforming data into insights that drive recommendations and decision-making</li><li>Work within AWS-Redshift and Tableau daily</li><li>Perform ad-hoc analysis with quick turnarounds uncovering insights and translating them into a story that is molded to your stakeholders perspective.</li><li>Support our Data Scientists as both a fact checker and liaison to the business: tracking the utilization and financial performance of their models</li><li>Represents Advanced Analytics in meetings or presentations as needed</li><li>Performs other related duties as required or requested.</li><li>Bachelor’s degree required, preferably in Business Analytics, Engineering, Computer Science, Statistics, or related field</li><li>5+ years’ experience in an analytically intense field or subject area</li><li>Technical programming experience: SQL, Python, R, SAS, MATLAB etc.</li><li>Practical experience using Tableau</li><li>Must have excellent analytical and problem-solving skills</li><li>Able to communicate and collaborate well to understand business needs and deliver data driven insights with efficiency and accuracy</li><li>Strong organizational and time management skills with the ability to handle diverse and significant workload.</li><li>Deep knowledge and proficiency using PC based packages such as SQL, Excel, PowerPoint, Outlook</li><li>Downers Grove, IL</li><li>Woodlands, TX</li><li>Dublin, OH</li><li>The salary range is $83,650 - $104,570. This role is also eligible for incentive pay.</li><li>The specific salary offered to a candidate may be motivated by a variety of factors including the candidate’s meaningful experience, education, training, certifications, qualifications, and work location.</li><li>Available employee benefits include health, vision, and dental. We also provide 401k matching for retirement and flexible time off.</li><li>Strong work/life flexibility</li><li>To be surrounded by an inclusive team who is collaborative and committed to the achievement of the company</li><li>To be rewarded for your contributions with a targeted annual company bonus and annual salary reviews</li><li>Competitive pay and benefits</li>
</ul>
</div>
</div>
<div class="job-card">
<div class="job-title">#20 Artificial Intelligence Engineer — Score: 0.36 (Raw: 0.36)</div>
<div class="company-location">AddSource | Rosemont, IL</div>
<div><a href="https://www.linkedin.com/jobs/view/artificial-intelligence-engineer-at-addsource-4267516679?position=8&amp;pageNum=0&amp;refId=tpX2%2BoTMGkfd7tjpAn087Q%3D%3D&amp;trackingId=4RYq3Yhi1Jaic9Bh3p8YBg%3D%3D" style="font-weight: bold;" target="_blank">View Job Posting</a></div>
<div class="keywords">Keywords: {'data', 'users', 'Engineering', 'control'}</div>
<div class="description">
<ul>
<li>What is in it for you?</li><li>As an AI Engineer, you will be a part of an Agile team to build healthcare applications and implement new features while adhering to the best coding development standards.</li><li>Overview:</li><li>We're looking for a skilled contractor to collaboratively help us accelerate our implementation and adoption of Microsoft Copilot-based agentic solutions across our enterprise.</li><li>This role is central to our strategy of leveraging Microsoft Copilot Studio and Power Automate to build intelligent agents that streamline workflows, enhance productivity, and improve internal enterprise-user experiences.</li><li>You'll work closely with both technical and non-technical stakeholders to design, build, and deploy these agents—bringing AI-powered, agentic, automation to life in practical, maintainable, ways.</li><li>If you're passionate about building intelligent agents using Microsoft Copilot, and excited by the opportunity to shape how AI is applied to real-world business processes, this is your chance to make a meaningful impact.</li><li>You'll play a key role in helping us get there - both guiding the direction and paving the road</li><li>Key Responsibilities:</li><li>Build agents within the Microsoft Copilot ecosystem, including Power Automate and external integrations, to support specific business functions, including HR, finance, and sales</li><li>Design and implement scalable workflows that integrate with Microsoft 365, SharePoint, Teams, and other enterprise systems</li><li>Collaborate with users to identify agentic AI opportunities, refine requirements, and support usage</li><li>Serve as a subject matter expert on best practices, patterns, and implementation strategies</li><li>Assist in the setup and agentic governance, including version control and lifecycle management</li><li>Provide expert-level guidance to internal IT team on Microsoft Copilot best practices and technical implementations.</li><li>Create documentation that supports this guidance.</li><li>Key Qualifications:</li><li>Demonstrated experience deploying Microsoft Copilot-built and hosted agents to production</li><li>Expertise in designing, building, and deploying Power Automate workflows to support Copilot agents</li><li>Strong understanding of version control and CI/CD processes for building and deploying agents</li><li>Ability to lead and contribute to user conversations, refinement sessions, and requirements discussions</li><li>Proven ability to provide expert-level advice and guidance to internal teams</li><li>Strong understanding of agent-based AI systems (e.g., task-oriented agents, autonomous workflows) and their application in enterprise environments</li><li>Experience with workflow automation, CRM integration, and data governance</li><li>Ability to work independently and collaboratively</li><li>Excellent communication and documentation skills</li><li>Experience: -</li><li>· 8+ Years</li><li>Duration: 6 Months</li><li>Location: Hybrid (Rosemont, IL, in-person TUE thru THUR)</li><li>Educational Qualifications: -</li><li>Engineering Degree – BE/ME/BTech/MTech/BSc/MSc.</li><li>Technical certification in multiple technologies is desirable.</li>
</ul>
</div>
</div>
</body></html>